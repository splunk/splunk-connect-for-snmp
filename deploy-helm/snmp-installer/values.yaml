scheduler:
  logLevel: "WARN"
  index:
    event: em_logs
    metrics: em_metrics
    meta: em_meta
  resources:
    limits:
      cpu: 1000m
      memory: 2Gi
    requests:
      cpu: 1000m
      memory: 2Gi
  inventory:
    content: |-
      #10.0.0.1,2c,public,basev1,300
  config: |
    celery:
      broker:
        type: "rabbitmq"
    # Sample Configuration file
    ipv4: True
    ipv6: False
    communities:
      public:
        communityIndex:
        contextEngineId:
        contextName:
        tag:
        securityName:
      my-area:
    usernames:
      simulator:
        authKey: "auctoritas"
        privKey: "privatus"
      testUser:
        authKey: authpass
        privKey: privacypass
        contextName: "4c9184f37cff01bcdc32dc486ec36961"
        authProtocol: SHA
        privProtocol: AES
        securityEngineId: 8000000004030201
        securityName:
        authKeyType: 0
        privKeyType: 0
    profiles:
      basev1:
        varBinds:
          # Syntax: [ "MIB-Files", "MIB object name" "MIB index number"]
          - ['SNMPv2-MIB', 'sysDescr']
          - ['SNMPv2-MIB', 'sysUpTime',0]
          - ['SNMPv2-MIB', 'sysName']
      basev1l2:
        varBinds:
          # Syntax: [ "MIB-Files", "MIB object name" "MIB index number"]
          - ['SNMPv2-MIB', 'sysDescr']
          - ['SNMPv2-MIB', 'sysUpTime',0]
          - ['SNMPv2-MIB', 'sysName']
          - ['IF-MIB','ifHCInOctets']
          - ['IF-MIB','ifHCOutOctets']
          - ['IF-MIB','ifInErrors']
          - ['IF-MIB','ifOutErrors']
          - ['IF-MIB','ifInDiscards']
          - ['IF-MIB','ifOutDiscards']
    mongo:
      database: "snmp_poller"
      collection: "walked_hosts"
splunk:
  protocol: ###PROTOCOL###
  host: ###SPLUNK_HOST###
  insecureSSL: ###INSECURE_SSL###
  token: ###SPLUNK_TOKEN###
  port: ###SPLUNK_PORT###
  clusterName: ###CLUSTER_NAME###
traps:
  logLevel: "WARN"
  loadBalancerIP: ###X.X.X.X###
  version: 1
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      memory: 128Mi
  config: |
    # Splunk Connect for SNMP Traps
    # Sample Configuration file
    snmp:
      communities:
        v1:
          - public
          - "my-area"
        v2:
          - public
          - "my-area"
        v3:
          - userName: snmpv3test
            authKey: AuthPass1
            privKey: PrivPass2
            securityEngineId: 8000000004030201
          - userName: snmpv3test2
            authProtocol: SHA
            authKey: AuthPass11
            privProtocol: aes
            privKey: PrivPass22
            securityEngineId: 8000000004030202
          - userName: snmpv3test3
            securityEngineId: 8000000004030203
          - userName: testfdse
            authKey: testfdse
            privKey: testfdse
            securityEngineId: 8000000903bc16f5802780
    thread-pool:
      max-suggested-working-threads: 10
mode: "both"
mib:
  service_host: sc4snmp-mib-server-service
  service_port: "5000"
  version: 1
  resources:
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 100m
      memory: 128Mi
otel:
  service_host: otel-service
  service_metrics_port: "8882"
  service_logs_port: "8881"
worker:
  logLevel: "WARN"
  version: 1
  resources:
    limits:
      cpu: 200m
      memory: 256Mi
    requests:
      cpu: 200m
      memory: 256Mi
mongodb:
  ## @section Global parameters
  ## Global Docker image parameters
  ## Please, note that this will override the image parameters, including dependencies, configured to use the global value
  ## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass

  ## @section Common parameters
  ##

  ## @param fullnameOverride String to fully override mongodb.fullname template
  ##
  fullnameOverride: "sc4snmp-mongodb"
  ## @param clusterDomain Default Kubernetes cluster domain
  ##
  clusterDomain: cluster.local

  ##
  auth:
    ## @param auth.enabled Enable authentication
    ## ref: https://docs.mongodb.com/manual/tutorial/enable-authentication/
    ##
    enabled: false

  ## MongoDB&reg; containers' resource requests and limits.
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param resources.limits The resources limits for MongoDB&reg; containers
  ## @param resources.requests The requested resources for MongoDB&reg; containers
  ##
  resources:
    limits:
      cpu: 500m
      memory: 512Mi
    requests:
      cpu: 100m
      memory: 256Mi


  ## @section Volume Permissions parameters

  ## @section Metrics parameters

  metrics:
    ## @param metrics.enabled Enable using a sidecar Prometheus exporter
    ##
    enabled: true
    containerPort: 9216
    ## Prometheus Exporter service configuration
    ##
    service:
      ## @param metrics.service.annotations [object] Annotations for Prometheus Exporter pods. Evaluated as a template.
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
      ##
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9216"
rabbitmq:
  ## @section Common parameters

  ## @param nameOverride String to partially override rabbitmq.fullname template (will maintain the release name)
  ##
  nameOverride: "sc4snmp-rabbitmq"

  ## @param fullnameOverride String to fully override rabbitmq.fullname template
  ##
  fullnameOverride: "sc4snmp-rabbitmq"

  auth:
    ## @param auth.username RabbitMQ application username
    ## ref: https://github.com/bitnami/bitnami-docker-rabbitmq#environment-variables
    ##
    username: sc4snmp

    ## @param auth.password RabbitMQ application password
    ## ref: https://github.com/bitnami/bitnami-docker-rabbitmq#environment-variables
    ##
    password: "sc4snmp"

    ## @param auth.erlangCookie Erlang cookie to determine whether different nodes are allowed to communicate with each other
    ## ref: https://github.com/bitnami/bitnami-docker-rabbitmq#environment-variables
    ##
    erlangCookie: "9xdEl2TBqFJJMjtt3Bds1Fpdh9Wgs1YL"

  ## Loading a RabbitMQ definitions file to configure RabbitMQ
  ##
  loadDefinition:
    ## @param loadDefinition.enabled Enable loading a RabbitMQ definitions file to configure RabbitMQ
    ##
    enabled: false

  ## RabbitMQ containers' resource requests and limits
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param resources.limits The resources limits for RabbitMQ containers
  ## @param resources.requests The requested resources for RabbitMQ containers
  ##
  resources:
    limits: {}
#       cpu: 1000m
#       memory: 2Gi
    requests: {}
#       cpu: 1000m
#       memory: 2Gi

  ## @section Persistence parameters

  persistence:
    ## @param persistence.enabled Enable RabbitMQ data persistence using PVC
    ##
    enabled: true

    ## @param persistence.storageClass PVC Storage Class for RabbitMQ data volume
    ## If defined, storageClassName: <storageClass>
    ## If set to "-", storageClassName: "", which disables dynamic provisioning
    ## If undefined (the default) or set to null, no storageClassName spec is
    ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
    ##   GKE, AWS & OpenStack)
    ##
    storageClass: ""
    ## @param persistence.selector Selector to match an existing Persistent Volume
    ## selector:
    ##   matchLabels:
    ##     app: my-app
    ##
    selector: {}
    ## @param persistence.accessMode PVC Access Mode for RabbitMQ data volume
    ##
    accessMode: ReadWriteOnce

    ## @param persistence.existingClaim Provide an existing PersistentVolumeClaims
    ## The value is evaluated as a template
    ## So, for example, the name can depend on .Release or .Chart
    ##
    existingClaim: ""

    ## @param persistence.size PVC Storage Request for RabbitMQ data volume
    ## If you change this value, you might have to adjust `rabbitmq.diskFreeLimit` as well
    ##
    size: 8Gi

    ## @param persistence.volumes Additional volumes without creating PVC
    ##  - name: volume_name
    ##    emptyDir: {}
    ##
    volumes: []


