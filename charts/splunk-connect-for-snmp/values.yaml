# Default values for splunk-connect-for-snmp.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

################################################################################
# SC4SNMP image settings
################################################################################

image:
  # The registry and name of the SC4SNMP image to pull
  repository: ghcr.io/splunk/splunk-connect-for-snmp/container
  # The policy that specifies when the user wants the SC4SNMP images to be pulled
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  tag: ""

# Secrets to attach to the respective serviceaccount to pull docker images
imagePullSecrets: []

# SC4SNMP UI configuration
UI:
  enable: false
  frontEnd:
    NodePort: 30001
    repository: ghcr.io/splunk/sc4snmp-ui/frontend/container
    tag: "main"
    pullPolicy: "Always"
  backEnd:
    NodePort: 30002
    repository: ghcr.io/splunk/sc4snmp-ui/backend/container
    tag: "main"
    pullPolicy: "Always"
  # Base container that sets permissions for folders mounted to UI containers
  init:
    repository: registry.access.redhat.com/ubi9/ubi
    pullPolicy: IfNotPresent

  # valuesFileDirectory is obligatory if UI is used. It is a location of values.yaml and configuration files generated from the UI.
  valuesFileDirectory: ""

  # valuesFileName is an exact name of yaml file with user's configuration, located inside directory specified in
  # valuesFileDirectory. It is optional. If it is provided then this file fill be updated with configuration from the UI.
  # If the valuesFileName is empty, or provided file name can't be found inside valuesFileDirectory directory,
  # then configuration from the UI will be saved in few files, each file for different section, inside
  # valuesFileDirectory directory.
  valuesFileName: ""

  # If keepSectionFiles is set to true, separate configration files for different sections will be saved in
  # valuesFileDirectory directory regardless of valuesFileName proper configuration.
  keepSectionFiles: false

flower:
  enabled: false
  port: 80
  loadBalancerIP: ''

################################################################################
# Splunk Cloud / Splunk Enterprise configuration.
################################################################################

splunk:
  # Enables sending data to Splunk
  enabled: true
  # the protocol of the HEC endpoint: https or http
  protocol: ""
  # the port of the HEC endpoint
  port: "8088"
  # IP address or a domain name of a Splunk instance to send data to.
  host: ""
  # the protocol, host and port given here makes up to a HEC endpoint
  # according to the pattern: {{protocol}}://{{host}}:{{port}}/services/collector
  # for ex. https://splunk-endpoint:8088/services/collector

  # Required for Splunk Enterprise/Cloud (if `enabled` is set to true). Splunk
  # HTTP Event Collector token.
  token: 00000000-0000-0000-0000-000000000000
  # Whether to skip checking the certificate of the HEC endpoint when sending
  # data over HTTPS.
  insecureSSL: "false"

  # sourcetype for trap events
  sourcetypeTraps: "sc4snmp:traps"

  # sourcetype for non-metric polling event
  sourcetypePollingEvents: "sc4snmp:event"

  # sourcetype for metric polling event
  sourcetypePollingMetrics: "sc4snmp:metric"

  # name of the event index
  eventIndex: "netops"

  # name of the metrics index
  metricsIndex: "netmetrics"

################################################################################
# Splunk Observability configuration
################################################################################

sim:
  # Enables sending data to Splunk Observability/SignalFx.
  enabled: false
  # Splunk Observability org access token.
  # Required for Splunk Observability (if `realm` is specified).
  signalfxToken: ""
  # Splunk Observability realm to send telemetry data to.
  signalfxRealm: ""

  resources: {}
    # limits:
    #   cpu: 500m
    #   memory: 512Mi
    # requests:
    #   cpu: 200m
    #   memory: 256Mi


  service:
    # Here you can define annotations to append under sim service
    annotations: {}

  secret:
    # Option for creating a new secret or using an existing one.
    # When secret.create=true, a new kubernetes secret will be created by the helm chart that will contain the
    # values from sim.signalfxToken and sim.signalfxRealm.
    # When secret.create=false, the user must set secret.name to a name of a k8s secret the user created.
    create: true
    name: ""

  replicaCount: 1
  autoscaling:
    enabled: false

  podAnnotations: {}
  podAntiAffinity: soft
  nodeSelector: {}

################################################################################
# SC4SNMP components settings
################################################################################

scheduler:
  ### Group definitions ###
  # Create the group definition in case you want to configure polling from multiple hosts
  # at once, more on this: https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/configuring-groups/

  #groups: |
  #  example_group_1:
  #    - address: 10.202.4.202
  #      port: 161
  #    - address: 63.2.40.0
  #      port: 161
  groups: ""


  ### Profiles definitions ###
  # Create a profile definition to set varbinds you want to poll from the device.
  # more on this: https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/configuring-profiles/

  #profiles: |
  #  smart_profile:
  #    frequency: 100
  #    condition:
  #      type: field
  #      field: "SNMPv2-MIB.sysDescr"
  #      patterns:
  #        - '.*linux.*'
  #    varBinds:
  #      - ['SNMPv2-MIB']
  #      - ['SNMPv2-MIB', 'sysName']
  #      - ['SNMPv2-MIB', 'sysUpTime',0]
  #  static_profile:
  #    frequency: 300
  #    varBinds:
  #      - ['IP-MIB']
  #  small_walk:
  #    condition:
  #      type: "walk"
  #    varBinds:
  #      - ['IF-MIB', 'ifDescr']
  #      - ['IF-MIB', 'ifAdminStatus']
  #      - ['IF-MIB', 'ifOperStatus']
  #      - ['IF-MIB', 'ifName']
  #      - ['IF-MIB', 'ifAlias']
  #      - ['IF-MIB', 'ifIndex']
  #  conditional_profile:
  #    frequency: 30
  #    conditions:
  #      - field: IF-MIB.ifAdminStatus
  #        operation: "equals"
  #        value: "up"
  #      - field: IF-MIB.ifOperStatus
  #        operation: "equals"
  #        value: "up"
  #    varBinds:
  #      - ['IF-MIB', 'ifDescr']
  #      - ['IF-MIB', 'ifAlias']
  #      - ['IF-MIB', 'ifInErrors']
  #      - ['IF-MIB', 'ifOutDiscards']
  profiles: ""

  # mapping MIB fields to custom names
  # more: https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/configuring-profiles/#custom-translations
  customTranslations: {}

  # set CPU and Memory limits for a scheduler pod
  resources: {}
#     limits:
#       cpu: 800m
#       memory: 512Mi
#     requests:
#       cpu: 500m
#       memory: 256Mi
  # logging level, possible options: DEBUG, INFO, WARNING, ERROR, CRITICAL, or FATAL
  logLevel: "INFO"
  podAnnotations: {}
  podAntiAffinity: soft
  nodeSelector: {}

  # tasks expirations time in seconds
  tasksExpiryTime: 60

poller:
  # Appending OID indexes to metrics.
  # https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/poller-configuration/#append-oid-index-part-to-the-metrics
  metricsIndexingEnabled: false

  # Enable polling base profiles (with IF-MIB and SNMPv2-MIB) from
  # https://github:com/splunk/splunk-connect-for-snmp/blob/main/splunk_connect_for_snmp/profiles/base.yaml
  pollBaseProfiles: true

  # Sometimes SNMP Agent cannot accept more than X OIDs per once, so if the error "TooBig" is visible in logs,
  # decrease the number
  maxOidToProcess: 70

  # list of kubernetes secrets name that will be used for polling
  # https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/poller-configuration/#define-usernamesecrets
  usernameSecrets: []

  # Here is where polling happens. Learn more on how to configure it here:
  # https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/poller-configuration/

  #inventory: |
  #  address,port,version,community,secret,security_engine,walk_interval,profiles,smart_profiles,delete
  #  example_group_1,,2c,public,,,3000,static_profile,t,
  logLevel: "INFO"

worker:
  # workers are responsible for the actual execution of polling, processing trap messages, and sending data to Splunk.
  # More: https://splunk.github.io/splunk-connect-for-snmp/main/microk8s/configuration/worker-configuration/

  # The poller worker consumes all the tasks related to polling
  poller:
    # number of the poller replicas when autoscaling is set to false
    replicaCount: 2
    # minimum number of threads in a pod
    concurrency: 4
    # how many tasks are consumed from the queue at once
    prefetch: 1
    autoscaling:
      # enabling autoscaling for poller worker pods
      enabled: false
      # minimum number of running poller worker pods when autoscaling is enabled
      minReplicas: 2
      # maximum number of running poller worker pods when autoscaling is enabled
      maxReplicas: 10
      # CPU % threshold that must be exceeded on poller worker pods to spawn another replica
      targetCPUUtilizationPercentage: 80

    resources:
      # the resources limits for poller worker container
      limits:
        cpu: 500m
      # the resources requests for poller worker container
      requests:
        cpu: 250m

  # The trap worker consumes all the trap related tasks produced by the trap pod
  trap:
    # number of the trap replicas when autoscaling is set to false
    replicaCount: 2
    # Use reverse dns lookup of trap ip address and send the hostname to splunk
    resolveAddress:
      enabled: false
      cacheSize: 500 # maximum number of records in cache
      cacheTTL: 1800 # time to live of the cached record in seconds
    # minimum number of threads in a pod
    concurrency: 4
    # how many tasks are consumed from the queue at once
    prefetch: 30
    autoscaling:
      # enabling autoscaling for trap worker pods
      enabled: false
      # minimum number of running trap worker pods when autoscaling is enabled
      minReplicas: 2
      # maximum number of running trap worker pods when autoscaling is enabled
      maxReplicas: 10
      # CPU % threshold that must be exceeded on traps worker pods to spawn another replica
      targetCPUUtilizationPercentage: 80
    resources:
      # the resources limits for trap worker container
      limits:
        cpu: 500m
      requests:
        # the resources requests for trap worker container
        cpu: 250m
  # The sender worker handles sending data to Splunk
  sender:
    # number of the sender replicas when autoscaling is set to false
    replicaCount: 1
    # minimum number of threads in a pod
    concurrency: 4
    # how many tasks are consumed from the queue at once
    prefetch: 30
    autoscaling:
      # enabling autoscaling for sender worker pods
      enabled: false
      # minimum number of running sender worker pods when autoscaling is enabled
      minReplicas: 2
      # maximum number of running sender worker pods when autoscaling is enabled
      maxReplicas: 10
      # CPU % threshold that must be exceeded on sender worker pods to spawn another replica
      targetCPUUtilizationPercentage: 80
    resources:
      # the resources limits for sender worker container
      limits:
        cpu: 500m
        # the resources requests for sender worker container
      requests:
        cpu: 250m
  # Liveness probes are used in Kubernetes to know when a pod is alive or dead.
  # A pod can be in a dead state for a number of reasons;
  # the application could be crashed, some error in the application etc.
  livenessProbe:
    # whether it should be turned on or not
    enabled: false
    # The exec command for the liveness probe to run in the container.
    exec:
      command:
        - sh
        - -c
        - test $(($(date +%s) - $(stat -c %Y /tmp/worker_heartbeat))) -lt 10
    # Number of seconds after the container has started before liveness probes are initiated.
    initialDelaySeconds: 80
    # How often (in seconds) to perform the probe.
    periodSeconds: 10

  # Readiness probes are used to know when a pod is ready to serve traffic.
  # Until a pod is ready, it won't receive traffic from Kubernetes services.
  readinessProbe:
    # whether it should be turned on or not
    enabled: false
    # The exec command for the readiness probe to run in the container.
    exec:
      command:
        - sh
        - -c
        - test -e /tmp/worker_ready
    # Number of seconds after the container has started before readiness probes are initiated.
    initialDelaySeconds: 30
    # How often (in seconds) to perform the probe.
    periodSeconds: 5


  # task timeout in seconds (usually necessary when walk process takes a long time)
  taskTimeout: 2400
  # maximum time interval between walk attempts
  walkRetryMaxInterval: 180
  # maximum number of walk retries
  walkMaxRetries: 5
  # ignoring `occurred: OID not increasing` issues for hosts specified in the array, ex:
  #   ignoreNotIncreasingOid:
  #    - "127.0.0.1:164"
  #    - "127.0.0.6"
  ignoreNotIncreasingOid: []
  # logging level, possible options: DEBUG, INFO, WARNING, ERROR, CRITICAL, or FATAL
  logLevel: "INFO"
  podAntiAffinity: soft
  # udpConnectionTimeout timeout in seconds for SNMP operations
  udpConnectionTimeout: 3

  # in case of seeing "Empty SNMP response message" this variable can be set to true
  ignoreEmptyVarbinds: false

  nodeSelector: {}

inventory:
  secret:
    # Option for creating a new secret or using an existing one.
    # When secret.create=true, a new kubernetes secret will be created by the helm chart that will contain the
    # values from sim.signalfxToken and sim.signalfxRealm.
    # When secret.create=false, the user must set secret.name to a name of a k8s secret the user created.
    create: true
    name: ""

  service:
    annotations: {}

  # set CPU and Memory limits for an inventory pod
  resources: {}
  #  limits:
  #    cpu: 800m
  #    memory: 512Mi
  #  requests:
  #    cpu: 500m
  #    memory: 256Mi

  nodeSelector: {}
  tolerations: []

traps:
  # this is a simple server that can handle SNMP traps sent by SNMP devices like routers or switches.

  # number of the traps receivers replicas when autoscaling is set to false
  # it makes sense to increase it in case there are hundreds of traps per seconds
  replicaCount: 2
  # usernameSecrets section define SNMPv3 secrets for trap messages sent by SNMP device
  usernameSecrets: []
  # SNMPv3 TRAPs require the configuration SNMP Engine ID of the TRAP sending application for the USM users table
  # of the TRAP receiving application for each USM user
  securityEngineId:
    - "80003a8c04"
  # aggregateTrapsEvents flag set to true makes traps events collected as one event inside splunk
  aggregateTrapsEvents: "false"

  # communities define a version of SNMP protocol and SNMP community string, which should be used
  communities: {}

  service:
    annotations: {}
    # this settings set metallb.universe.tf/allow-shared-ip annotation in trap service
    # was introduced to allow using splunk-connect-for-syslog on the same machine
    usemetallb: true
    metallbsharingkey: "splunk-connect"
    # when using SC4SNMP on a standalone k8s installation, LoadBalancer is a good choice
    # on a multi-node it's better to set this as NodePort and configure traps.service.nodePort
    type: LoadBalancer
    port: 162

    # nodePort will be set only when type of service is a NodePort
    #nodePort: 30000

  #loadBalancerIP must be set to the IP address in the metallb pool.
  #It is required when service type is set to LoadBalancer.
  #loadBalancerIP: 18.117.100.37
  loadBalancerIP: ""
  ipFamilyPolicy: SingleStack
  ipFamilies:
   - IPv4

  resources: {}
    # limits:
    #   cpu: 1
    #   memory: 1Gi
    # requests:
    #   cpu: 200m
    #   memory: 256Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  # logging level, possible options: DEBUG, INFO, WARNING, ERROR, CRITICAL, or FATAL
  logLevel: "INFO"
  nodeSelector: {}
  tolerations: []
  podAntiAffinity: soft


serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# This parameter allows to use SC4SNMP for older version of Kubernetes that doesn't support autoscaling/v2
useDeprecatedAPI: false

#############################################################################
### Please do not modify below values, unless you know what you're doing! ###
#############################################################################
mongodb:
  architecture: "standalone"
  updateStrategy:
    type: Recreate
  initdbScripts:
    setFeatureCompatibilityVersion.js: |
      db.adminCommand({ setFeatureCompatibilityVersion: "6.0" });

  ## @section Global parameters
  ## Global Docker image parameters
  ## Please, note that this will override the image parameters, including dependencies, configured to use the global value
  ## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass

  ## @section Common parameters
  ##

  ## @param clusterDomain Default Kubernetes cluster domain
  ##
  clusterDomain: cluster.local

  ##
  auth:
    ## @param auth.enabled Enable authentication
    ## ref: https://docs.mongodb.com/manual/tutorial/enable-authentication/
    ##
    enabled: false

  ## MongoDB&reg; containers' resource requests and limits.
  ## ref: http://kubernetes.io/docs/user-guide/compute-resources/
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  ## @param resources.limits The resources limits for MongoDB&reg; containers
  ## @param resources.requests The requested resources for MongoDB&reg; containers
  ##
  rbac:
    create: true
  resources: {}
    # limits:
    #   cpu: 1000m
    #   memory: 768Mi
    # requests:
    #   cpu: 250m
    #   memory: 512Mi

  ## @section Volume Permissions parameters

  ## @section Metrics parameters

  metrics:
    ## @param metrics.enabled Enable using a sidecar Prometheus exporter
    ##
    enabled: true
    containerPort: 9216
    ## Prometheus Exporter service configuration
    ##
    service:
      ## @param metrics.service.annotations [object] Annotations for Prometheus Exporter pods. Evaluated as a template.
      ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/
      ##
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "9216"
  pdb:
    create: true

  ## In MicroK8s there is an addon providing PersistentVolumes.
  ## "microk8s-hostpath" is the default storageClassName ref: https://microk8s.io/docs/addon-hostpath-storage.
  ## If something else than MicroK8s is used, then persistence.storageClass needs to be adjusted accordingly:
  ## ref: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#class-1
  persistence:
    storageClass: "microk8s-hostpath"
  volumePermissions:
    enabled: true
redis:
  architecture: standalone
  auth:
    enabled: false
commonAnnotations: {}
